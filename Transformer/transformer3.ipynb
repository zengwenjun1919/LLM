{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一步：构建训练数据\n",
    "生成一批随机的序列数据（源序列和目标序列），并对它们做填充操作，使每个序列的长度一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 1, 0, 0, 0],\n",
      "        [5, 7, 5, 2, 0]])\n",
      "tensor([[4, 1, 6, 3, 0],\n",
      "        [1, 3, 3, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "#生成一批随机的序列数据（源序列和目标序列），并对它们做填充操作，使每个序列的长度一致\n",
    "batch_size = 2\n",
    "#单词表大小\n",
    "max_num_src_words = 8  # 原序列单词的总数是8\n",
    "max_num_tgt_words = 8  # 目标序列单词的总数是8\n",
    "model_dim = 8 #模型的特征大小 原始模型是512 向量维度\n",
    "\n",
    "# 序列的最大长度\n",
    "max_src_seq_len = 5  # 定义一个全局的量\n",
    "max_tgt_seq_len = 5  # 定义一个全局的量\n",
    "max_position_len =5\n",
    "\n",
    "src_len = torch.Tensor([2, 4]).to(torch.int32)  # 每个源序列的实际长度\n",
    "tgt_len = torch.Tensor([4, 3]).to(torch.int32)  # 每个目标序列的实际长度\n",
    "\n",
    "# 将 `src_len` 和 `tgt_len` 转换为 Python 的整数列表  \n",
    "src_len = [int(L.item()) for L in src_len]\n",
    "tgt_len = [int(L.item()) for L in tgt_len]\n",
    "\n",
    "# 单词索引构成源句子和目标句子，构建batch，并且做了padding,默认值为0\n",
    "# 对源序列进行填充\n",
    "src_seq = torch.cat([\n",
    "    torch.unsqueeze(F.pad(\n",
    "        torch.randint(1, max_num_src_words, (L,)),  # 创建随机序列，长度为 L\n",
    "        (0, max_src_seq_len - L)  # 填充到 `max_src_seq_len` 长度\n",
    "    ),0) for L in src_len\n",
    "])\n",
    "\n",
    "# 对目标序列进行填充(原序列变成二维张量)\n",
    "tgt_seq = torch.cat([\n",
    "    torch.unsqueeze(F.pad(\n",
    "        torch.randint(1, max_num_tgt_words, (L,)),  # 创建随机序列，长度为 L\n",
    "        (0, max_tgt_seq_len - L)  # 填充到 `max_src_seq_len` 长度\n",
    "    ),0) for L in tgt_len\n",
    "])\n",
    "\n",
    "# 打印结果\n",
    "print(src_seq)\n",
    "print(tgt_seq)\n",
    "\n",
    "#以上代码 用单词索引构成源句子和目标句子，并且做了padding,默认值为0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二步 构造embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-1.5087,  1.2219,  0.5087, -0.8259,  1.3889, -1.4976,  0.9455,  0.0100],\n",
      "        [ 0.4668, -1.1043, -0.3958, -0.5707,  1.3332, -0.5401, -0.2981, -1.7680],\n",
      "        [ 1.8742, -0.6843,  0.0766, -0.4398, -0.1407, -0.8353, -0.5706,  0.1183],\n",
      "        [-1.1911,  0.1569, -0.8556,  0.5601, -0.7699, -0.5574, -0.9442, -1.0084],\n",
      "        [ 1.4479, -2.0268,  0.1048,  0.1303,  1.3609,  0.6003, -0.4600, -0.2033],\n",
      "        [ 0.1169,  0.2863,  0.3168,  0.4440, -0.9636, -1.5183,  1.7822, -0.4421],\n",
      "        [-0.8873,  0.1426,  0.1239,  0.6848, -1.0032, -0.2704,  1.2433, -1.5858],\n",
      "        [ 1.6517,  0.3482,  0.8908, -0.3106,  0.9982,  1.2933,  0.4415, -1.4029],\n",
      "        [-1.6846, -1.0505,  0.9793,  0.8035, -0.0986,  0.8689, -0.0112, -0.6706]],\n",
      "       requires_grad=True)\n",
      "tensor([[5, 1, 0, 0, 0],\n",
      "        [5, 7, 5, 2, 0]])\n",
      "tensor([[[ 0.1169,  0.2863,  0.3168,  0.4440, -0.9636, -1.5183,  1.7822,\n",
      "          -0.4421],\n",
      "         [ 0.4668, -1.1043, -0.3958, -0.5707,  1.3332, -0.5401, -0.2981,\n",
      "          -1.7680],\n",
      "         [-1.5087,  1.2219,  0.5087, -0.8259,  1.3889, -1.4976,  0.9455,\n",
      "           0.0100],\n",
      "         [-1.5087,  1.2219,  0.5087, -0.8259,  1.3889, -1.4976,  0.9455,\n",
      "           0.0100],\n",
      "         [-1.5087,  1.2219,  0.5087, -0.8259,  1.3889, -1.4976,  0.9455,\n",
      "           0.0100]],\n",
      "\n",
      "        [[ 0.1169,  0.2863,  0.3168,  0.4440, -0.9636, -1.5183,  1.7822,\n",
      "          -0.4421],\n",
      "         [ 1.6517,  0.3482,  0.8908, -0.3106,  0.9982,  1.2933,  0.4415,\n",
      "          -1.4029],\n",
      "         [ 0.1169,  0.2863,  0.3168,  0.4440, -0.9636, -1.5183,  1.7822,\n",
      "          -0.4421],\n",
      "         [ 1.8742, -0.6843,  0.0766, -0.4398, -0.1407, -0.8353, -0.5706,\n",
      "           0.1183],\n",
      "         [-1.5087,  1.2219,  0.5087, -0.8259,  1.3889, -1.4976,  0.9455,\n",
      "           0.0100]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#把文本句子变成一个个数字 （单词在词典中的位置）【第0个位置留给padding]\n",
    "src_embedding_table = nn.Embedding(max_num_src_words+1,model_dim)\n",
    "tgt_embedding_table = nn.Embedding(max_num_tgt_words+1,model_dim)\n",
    "src_embedding = src_embedding_table(src_seq)#输入的embedding\n",
    "tgt_embedding = tgt_embedding_table(tgt_seq)#输出的embedding\n",
    "\n",
    "print(src_embedding_table.weight)\n",
    "print(src_seq)\n",
    "print(src_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造position embedding--位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.8415,  0.0000,  0.0998,  0.0000,  0.0100,  0.0000,  0.0010,  0.0000],\n",
      "        [ 0.9093,  0.0000,  0.1987,  0.0000,  0.0200,  0.0000,  0.0020,  0.0000],\n",
      "        [ 0.1411,  0.0000,  0.2955,  0.0000,  0.0300,  0.0000,  0.0030,  0.0000],\n",
      "        [-0.7568,  0.0000,  0.3894,  0.0000,  0.0400,  0.0000,  0.0040,  0.0000]])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.8415,  0.0000,  0.0998,  0.0000,  0.0100,  0.0000,  0.0010,  0.0000],\n",
      "        [ 0.9093,  0.0000,  0.1987,  0.0000,  0.0200,  0.0000,  0.0020,  0.0000],\n",
      "        [ 0.1411,  0.0000,  0.2955,  0.0000,  0.0300,  0.0000,  0.0030,  0.0000],\n",
      "        [-0.7568,  0.0000,  0.3894,  0.0000,  0.0400,  0.0000,  0.0040,  0.0000]])\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.8415, 0.0000, 0.0998, 0.0000, 0.0100, 0.0000, 0.0010, 0.0000],\n",
      "         [0.9093, 0.0000, 0.1987, 0.0000, 0.0200, 0.0000, 0.0020, 0.0000],\n",
      "         [0.1411, 0.0000, 0.2955, 0.0000, 0.0300, 0.0000, 0.0030, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.8415, 0.0000, 0.0998, 0.0000, 0.0100, 0.0000, 0.0010, 0.0000],\n",
      "         [0.9093, 0.0000, 0.1987, 0.0000, 0.0200, 0.0000, 0.0020, 0.0000],\n",
      "         [0.1411, 0.0000, 0.2955, 0.0000, 0.0300, 0.0000, 0.0030, 0.0000]]])\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.8415, 0.0000, 0.0998, 0.0000, 0.0100, 0.0000, 0.0010, 0.0000],\n",
      "         [0.9093, 0.0000, 0.1987, 0.0000, 0.0200, 0.0000, 0.0020, 0.0000],\n",
      "         [0.1411, 0.0000, 0.2955, 0.0000, 0.0300, 0.0000, 0.0030, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.8415, 0.0000, 0.0998, 0.0000, 0.0100, 0.0000, 0.0010, 0.0000],\n",
      "         [0.9093, 0.0000, 0.1987, 0.0000, 0.0200, 0.0000, 0.0020, 0.0000],\n",
      "         [0.1411, 0.0000, 0.2955, 0.0000, 0.0300, 0.0000, 0.0030, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "pos_mat = torch.arange(max_position_len).reshape((-1,1))\n",
    "i_mat = torch.pow(10000,torch.arange(0,8,2).reshape((1,-1))/model_dim)\n",
    "pe_embedding_table = torch.zeros(max_position_len,model_dim)\n",
    "pe_embedding_table[:,0::2] = torch.sin(pos_mat / i_mat )\n",
    "print(pe_embedding_table)\n",
    "\n",
    "\n",
    "print(pe_embedding_table)\n",
    "pe_embedding = nn.Embedding(max_position_len,model_dim)\n",
    "pe_embedding.weight = nn.Parameter(pe_embedding_table,requires_grad=False)\n",
    "\n",
    "src_pos = torch.cat([torch.unsqueeze(torch.arange(max(src_len)),0) for _ in src_len]).to(torch.int32)\n",
    "tgt_pos = torch.cat([torch.unsqueeze(torch.arange(max(tgt_len)),0) for _ in tgt_len]).to(torch.int32)\n",
    "\n",
    "src_pe_embedding = pe_embedding(src_pos)\n",
    "tgt_pe_embedding = pe_embedding(tgt_pos)\n",
    "print(src_pe_embedding)\n",
    "print(tgt_pe_embedding)\n",
    "#借助pytorch 的nn 通过位置索引 直接得到位置embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7771, -0.1134, -0.3330, -0.6906,  1.1090])\n",
      "tensor([0.1876, 0.2005, 0.1961, 0.1892, 0.2265])\n",
      "tensor([6.4415e-09, 4.9141e-06, 5.4680e-07, 1.5293e-08, 9.9999e-01])\n",
      "tensor([[ 0.1524, -0.0376, -0.0368, -0.0355, -0.0425],\n",
      "        [-0.0376,  0.1603, -0.0393, -0.0379, -0.0454],\n",
      "        [-0.0368, -0.0393,  0.1577, -0.0371, -0.0444],\n",
      "        [-0.0355, -0.0379, -0.0371,  0.1534, -0.0429],\n",
      "        [-0.0425, -0.0454, -0.0444, -0.0429,  0.1752]])\n",
      "tensor([[ 6.4415e-09, -3.1655e-14, -3.5222e-15, -9.8511e-17, -6.4415e-09],\n",
      "        [-3.1655e-14,  4.9141e-06, -2.6871e-12, -7.5153e-14, -4.9141e-06],\n",
      "        [-3.5222e-15, -2.6871e-12,  5.4680e-07, -8.3623e-15, -5.4680e-07],\n",
      "        [-9.8511e-17, -7.5153e-14, -8.3623e-15,  1.5293e-08, -1.5293e-08],\n",
      "        [-6.4415e-09, -4.9141e-06, -5.4680e-07, -1.5293e-08,  5.4836e-06]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_22604\\2085042164.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(score)\n"
     ]
    }
   ],
   "source": [
    "#softmax演示 scaled的重要性\n",
    "#alpha1 = 0.1#加入参数\n",
    "#alpha2 = 10\n",
    "#score = torch.randn(5)#假设有一个向量长度为5 q*k\n",
    "#prob1 = F.softmax(score * alpha1,-1)#要归一化--为了算注意力机制 用softmax函数\n",
    "#prob2 = F.softmax(score * alpha2,-1)\n",
    "#print(score)#一个单词跟整个序列5个单词 他们的相似度的结果\n",
    "#print(prob1)#prob越大表示这两个单词之间的关联性就越大\n",
    "#print(prob2)#乘以一个更大的值 score进行缩放 发现不是一个线性\n",
    "\n",
    "#def softmax_func(score):\n",
    "    #return F.softmax(score)\n",
    "#jaco_mat1 = torch.autograd.functional.jacobian(softmax_func,score*alpha1)\n",
    "#jaco_mat2 = torch.autograd.functional.jacobian(softmax_func,score*alpha2)\n",
    "\n",
    "#print(jaco_mat1)\n",
    "#print(jaco_mat2)#很多地方变成了0  没法测试 更新缓慢---QK的方差比价大 所以要除以。。 这样把他的方差弄的小 这样出来的方差就不会尖锐 雅可比矩阵也不会是0 更好拟合模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4]\n",
      "tensor([[[ 0.1757,  0.3235,  1.4129, -2.4193,  0.5024],\n",
      "         [-0.0364, -1.1438, -0.5477, -0.4542,  0.2674],\n",
      "         [ 0.0181,  0.3356,  0.0515,  1.2012, -0.5275],\n",
      "         [ 1.0760,  0.1892,  0.1757,  0.0074, -0.0313],\n",
      "         [ 0.9178, -1.0964, -1.3748, -0.4647,  0.5871]],\n",
      "\n",
      "        [[-0.5212, -0.7235,  1.7528,  2.3971, -0.1821],\n",
      "         [-0.3758, -0.7509,  0.2712, -1.0049, -1.3839],\n",
      "         [-1.4135, -0.5290, -0.2983, -0.7322, -1.8117],\n",
      "         [-0.9284, -0.4624,  1.9035, -0.3858,  0.9875],\n",
      "         [-0.2232, -0.6820, -1.6235,  0.2576, -0.8895]]])\n",
      "tensor([[[ 1.7570e-01,  3.2354e-01, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [-3.6421e-02, -1.1438e+00, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
      "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09]],\n",
      "\n",
      "        [[-5.2123e-01, -7.2346e-01,  1.7528e+00,  2.3971e+00, -1.0000e+09],\n",
      "         [-3.7585e-01, -7.5086e-01,  2.7123e-01, -1.0049e+00, -1.0000e+09],\n",
      "         [-1.4135e+00, -5.2905e-01, -2.9833e-01, -7.3220e-01, -1.0000e+09],\n",
      "         [-9.2835e-01, -4.6240e-01,  1.9035e+00, -3.8576e-01, -1.0000e+09],\n",
      "         [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09]]])\n",
      "tensor([[[0.4631, 0.5369, 0.0000, 0.0000, 0.0000],\n",
      "         [0.7516, 0.2484, 0.0000, 0.0000, 0.0000],\n",
      "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
      "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000],\n",
      "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]],\n",
      "\n",
      "        [[0.0333, 0.0272, 0.3235, 0.6161, 0.0000],\n",
      "         [0.2421, 0.1664, 0.4624, 0.1291, 0.0000],\n",
      "         [0.1184, 0.2866, 0.3610, 0.2339, 0.0000],\n",
      "         [0.0470, 0.0748, 0.7974, 0.0808, 0.0000],\n",
      "         [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#构造encoder的self-attention mask\n",
    "#mask shape: [batch_size,max_src_len,max_src_len],值为1或-inf\n",
    "valid_encoder_pos = torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0,max_src_seq_len-L)),0) for L in src_len]),2)#构建有效矩阵 1 代表有效 0代表无效 pad填充 +扩维---有效的编码器位置矩阵 扩到第一维\n",
    "valid_encoder_pos_matrix = torch.bmm(valid_encoder_pos, valid_encoder_pos.transpose(1,2))\n",
    "invalid_encoder_pos_matrix = 1 - valid_encoder_pos_matrix#无效矩阵=1-有效矩阵\n",
    "mask_encoder_self_attention = invalid_encoder_pos_matrix.to(torch.bool)#变成bool型\n",
    "\n",
    "#randn(batch_size,max(src_len),max(src_len))\n",
    "#print(score.shape,mask_encoder_self_attention.shape)\n",
    "\n",
    "# 示例分数矩阵\n",
    "score = torch.randn(batch_size, max_src_seq_len, max_src_seq_len)\n",
    "\n",
    "masked_score = score.masked_fill(mask_encoder_self_attention,-1e9)#10^（-9）\n",
    "prob = F.softmax(masked_score,-1)\n",
    "\n",
    "\n",
    "#print(valid_encoder_pos.shape)#每一行都是一个sample 但是sample之间是无关的 所以我们要扩维\n",
    "#print(valid_encoder_pos_matrix)\n",
    "#print(invalid_encoder_pos_matrix)\n",
    "#print(mask_encoder_self_attention)\n",
    "print(src_len)\n",
    "print(score)\n",
    "print(masked_score)\n",
    "print(prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
